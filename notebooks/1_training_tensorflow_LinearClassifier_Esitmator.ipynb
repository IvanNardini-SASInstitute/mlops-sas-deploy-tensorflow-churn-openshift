{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "This notebook provides an example of how to train Tensorflow classifiers using the HMEQ dataset\n",
    "\n",
    "The goal is to predict whether a customer is a BAD (default) borrower, which in this dataset is a binary classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assumption\n",
    "\n",
    "We are working in big data context. \n",
    "\n",
    "Then, I'm going to work with HMEQ dataset as it is so large that it would not fit in RAM. \n",
    "\n",
    "Then we use the Tensorflow framework to deal with that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General\n",
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "\n",
    "#Analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR_PATH = os.getcwd()\n",
    "DATA_DIR_PATH = os.path.join(BASE_DIR_PATH, '../data')\n",
    "\n",
    "# Data directories paths\n",
    "TRAIN_DIR_PATH = os.path.join(DATA_DIR_PATH, 'train')\n",
    "TEST_DIR_PATH = os.path.join(DATA_DIR_PATH, 'test')\n",
    "VAL_DIR_PATH = os.path.join(DATA_DIR_PATH, 'val')\n",
    "\n",
    "# Data file paths\n",
    "TRAIN_DATA_PATH = os.path.join(TRAIN_DIR_PATH, 'train.csv')\n",
    "TEST_DATA_PATH = os.path.join(TEST_DIR_PATH, 'test.csv')\n",
    "VAL_DATA_PATH = os.path.join(VAL_DIR_PATH, 'val.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing data\n",
    "def _set_categorical_type(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''Set the categorical type as string if needed'''\n",
    "    for column in CATEGORICAL_VARIABLES:\n",
    "        if (dataframe[column].dtype == 'O'):\n",
    "            dataframe[column] = dataframe[column].astype('string')\n",
    "    return dataframe\n",
    "\n",
    "def _set_categorical_empty(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''Change object type for categorical variable to avoid TF issue '''\n",
    "    for column in CATEGORICAL_VARIABLES:\n",
    "        if any(dataframe[column].isna()):\n",
    "            dataframe[column] = dataframe[column].fillna('')\n",
    "    return dataframe\n",
    "\n",
    "def _set_numerical_type(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''Set the numerical type as float64 if needed'''\n",
    "    for column in NUMERICAL_VARIABLES:\n",
    "        if (dataframe[column].dtype == 'int64'):\n",
    "            dataframe[column] = dataframe[column].astype('float64')\n",
    "    return dataframe\n",
    "\n",
    "def _get_impute_parameters_cat(categorical_variables: list) -> dict:\n",
    "    '''For each column in the numerical features, calculate mean.'''\n",
    "    impute_parameters = {}\n",
    "    for column in categorical_variables:\n",
    "        impute_parameters[column] = 'Missing'\n",
    "    return impute_parameters\n",
    "    \n",
    "def _impute_missing_categorical(inputs: dict, target) -> dict:\n",
    "    impute_parameters = _get_impute_parameters_cat(CATEGORICAL_VARIABLES)\n",
    "    # Since we modify just some features, \n",
    "    # we need to start by setting `outputs` to a copy of `inputs.\n",
    "    output = inputs.copy()\n",
    "    for key, value in impute_parameters.items():\n",
    "        is_blank = tf.math.equal('', inputs[key])\n",
    "        tf_other = tf.constant(value, dtype=np.string_)\n",
    "        output[key] = tf.where(is_blank, tf_other, inputs[key])\n",
    "    return output, target\n",
    "\n",
    "def _get_mean_parameter(dataframe: pd.DataFrame, column: str) -> float:\n",
    "    ''' Given a column, calculate mean'''\n",
    "    mean = dataframe[column].mean()\n",
    "    return mean\n",
    "\n",
    "def _get_impute_parameters_num(dataframe: pd.DataFrame, numerical_variables: list) -> dict:\n",
    "    '''For each column in the numerical features, calculate mean.'''\n",
    "    impute_parameters = {}\n",
    "    for column in numerical_variables:\n",
    "        impute_parameters[column] = _get_mean_parameter(dataframe, column)\n",
    "    return impute_parameters\n",
    "\n",
    "def _impute_missing_numerical(inputs: dict, target) -> dict:\n",
    "    '''Impute missing based on training mean'''\n",
    "    impute_parameters = _get_impute_parameters_num(data_train, NUMERICAL_VARIABLES) ## Here we have data_train\n",
    "    # Since we modify just some features, \n",
    "    # we need to start by setting `outputs` to a copy of `inputs.\n",
    "    output = inputs.copy()\n",
    "    for key, value in impute_parameters.items():\n",
    "        is_miss = tf.math.is_nan(inputs[key])\n",
    "        tf_mean = tf.constant(value, dtype=np.float64)\n",
    "        output[key] = tf.where(is_miss, tf_mean, inputs[key])\n",
    "    return output, target\n",
    "            \n",
    "# A utility method to create a feature column\n",
    "# and to transform a batch of data\n",
    "def check_feature(feature_column):\n",
    "    feature_layer = layers.DenseFeatures(feature_column)\n",
    "    print(feature_layer(example_batch).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAD,LOAN,MORTDUE,VALUE,REASON,JOB,YOJ,DEROG,DELINQ,CLAGE,NINQ,CLNO,DEBTINC\r\n",
      "0,34400,97971.0,145124.0,DebtCon,Other,13.0,0.0,0.0,67.8320416646805,1.0,36.0,40.4027058419691\r\n",
      "0,13600,89937.0,110986.0,DebtCon,Sales,14.0,,2.0,146.718742448452,1.0,17.0,33.7471158335903\r\n",
      "1,10800,75000.0,87400.0,HomeImp,Other,7.0,1.0,0.0,101.46666666666701,2.0,19.0,\r\n",
      "0,14900,87167.0,114219.0,DebtCon,ProfExe,8.0,0.0,0.0,194.113173533089,2.0,36.0,41.3297639035293\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 ../data/train/train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BAD</th>\n",
       "      <th>LOAN</th>\n",
       "      <th>MORTDUE</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>REASON</th>\n",
       "      <th>JOB</th>\n",
       "      <th>YOJ</th>\n",
       "      <th>DEROG</th>\n",
       "      <th>DELINQ</th>\n",
       "      <th>CLAGE</th>\n",
       "      <th>NINQ</th>\n",
       "      <th>CLNO</th>\n",
       "      <th>DEBTINC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>34400</td>\n",
       "      <td>97971.0</td>\n",
       "      <td>145124.0</td>\n",
       "      <td>DebtCon</td>\n",
       "      <td>Other</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.832042</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>40.402706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>13600</td>\n",
       "      <td>89937.0</td>\n",
       "      <td>110986.0</td>\n",
       "      <td>DebtCon</td>\n",
       "      <td>Sales</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>146.718742</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>33.747116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10800</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>87400.0</td>\n",
       "      <td>HomeImp</td>\n",
       "      <td>Other</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.466667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>14900</td>\n",
       "      <td>87167.0</td>\n",
       "      <td>114219.0</td>\n",
       "      <td>DebtCon</td>\n",
       "      <td>ProfExe</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>194.113174</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>41.329764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>7200</td>\n",
       "      <td>98691.0</td>\n",
       "      <td>115750.0</td>\n",
       "      <td>HomeImp</td>\n",
       "      <td>Office</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118.000142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>37.720359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BAD   LOAN  MORTDUE     VALUE   REASON      JOB   YOJ  DEROG  DELINQ  \\\n",
       "0    0  34400  97971.0  145124.0  DebtCon    Other  13.0    0.0     0.0   \n",
       "1    0  13600  89937.0  110986.0  DebtCon    Sales  14.0    NaN     2.0   \n",
       "2    1  10800  75000.0   87400.0  HomeImp    Other   7.0    1.0     0.0   \n",
       "3    0  14900  87167.0  114219.0  DebtCon  ProfExe   8.0    0.0     0.0   \n",
       "4    0   7200  98691.0  115750.0  HomeImp   Office  22.0    0.0     0.0   \n",
       "\n",
       "        CLAGE  NINQ  CLNO    DEBTINC  \n",
       "0   67.832042   1.0  36.0  40.402706  \n",
       "1  146.718742   1.0  17.0  33.747116  \n",
       "2  101.466667   2.0  19.0        NaN  \n",
       "3  194.113174   2.0  36.0  41.329764  \n",
       "4  118.000142   0.0  11.0  37.720359  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_csv(TRAIN_DATA_PATH, sep=',')\n",
    "data_test = pd.read_csv(TEST_DATA_PATH, sep=',')\n",
    "data_val = pd.read_csv(VAL_DATA_PATH, sep=',')\n",
    "\n",
    "data_train.head(5)                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4827 entries, 0 to 4826\n",
      "Data columns (total 13 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   BAD      4827 non-null   int64  \n",
      " 1   LOAN     4827 non-null   int64  \n",
      " 2   MORTDUE  4405 non-null   float64\n",
      " 3   VALUE    4738 non-null   float64\n",
      " 4   REASON   4618 non-null   object \n",
      " 5   JOB      4601 non-null   object \n",
      " 6   YOJ      4419 non-null   float64\n",
      " 7   DEROG    4262 non-null   float64\n",
      " 8   DELINQ   4362 non-null   float64\n",
      " 9   CLAGE    4578 non-null   float64\n",
      " 10  NINQ     4421 non-null   float64\n",
      " 11  CLNO     4651 non-null   float64\n",
      " 12  DEBTINC  3804 non-null   float64\n",
      "dtypes: float64(9), int64(2), object(2)\n",
      "memory usage: 490.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BAD</th>\n",
       "      <td>4827.0</td>\n",
       "      <td>0.198674</td>\n",
       "      <td>0.399043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOAN</th>\n",
       "      <td>4827.0</td>\n",
       "      <td>18617.112078</td>\n",
       "      <td>11231.974061</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>11100.000000</td>\n",
       "      <td>16300.000000</td>\n",
       "      <td>23300.000000</td>\n",
       "      <td>89900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MORTDUE</th>\n",
       "      <td>4405.0</td>\n",
       "      <td>73796.339364</td>\n",
       "      <td>43741.460123</td>\n",
       "      <td>2063.000000</td>\n",
       "      <td>46884.000000</td>\n",
       "      <td>65206.000000</td>\n",
       "      <td>91491.000000</td>\n",
       "      <td>399412.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VALUE</th>\n",
       "      <td>4738.0</td>\n",
       "      <td>101633.021895</td>\n",
       "      <td>56564.609914</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>66260.250000</td>\n",
       "      <td>89407.500000</td>\n",
       "      <td>119732.500000</td>\n",
       "      <td>855909.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YOJ</th>\n",
       "      <td>4419.0</td>\n",
       "      <td>8.957377</td>\n",
       "      <td>7.604500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>41.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEROG</th>\n",
       "      <td>4262.0</td>\n",
       "      <td>0.244486</td>\n",
       "      <td>0.823733</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DELINQ</th>\n",
       "      <td>4362.0</td>\n",
       "      <td>0.446813</td>\n",
       "      <td>1.138853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLAGE</th>\n",
       "      <td>4578.0</td>\n",
       "      <td>179.902913</td>\n",
       "      <td>86.744368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>114.858318</td>\n",
       "      <td>173.497696</td>\n",
       "      <td>231.876088</td>\n",
       "      <td>1168.233561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NINQ</th>\n",
       "      <td>4421.0</td>\n",
       "      <td>1.199276</td>\n",
       "      <td>1.745287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLNO</th>\n",
       "      <td>4651.0</td>\n",
       "      <td>21.322081</td>\n",
       "      <td>10.111162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>71.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEBTINC</th>\n",
       "      <td>3804.0</td>\n",
       "      <td>33.768804</td>\n",
       "      <td>8.806656</td>\n",
       "      <td>0.524499</td>\n",
       "      <td>29.149239</td>\n",
       "      <td>34.818353</td>\n",
       "      <td>38.972750</td>\n",
       "      <td>203.312149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count           mean           std          min           25%  \\\n",
       "BAD      4827.0       0.198674      0.399043     0.000000      0.000000   \n",
       "LOAN     4827.0   18617.112078  11231.974061  1100.000000  11100.000000   \n",
       "MORTDUE  4405.0   73796.339364  43741.460123  2063.000000  46884.000000   \n",
       "VALUE    4738.0  101633.021895  56564.609914  8000.000000  66260.250000   \n",
       "YOJ      4419.0       8.957377      7.604500     0.000000      3.000000   \n",
       "DEROG    4262.0       0.244486      0.823733     0.000000      0.000000   \n",
       "DELINQ   4362.0       0.446813      1.138853     0.000000      0.000000   \n",
       "CLAGE    4578.0     179.902913     86.744368     0.000000    114.858318   \n",
       "NINQ     4421.0       1.199276      1.745287     0.000000      0.000000   \n",
       "CLNO     4651.0      21.322081     10.111162     0.000000     15.000000   \n",
       "DEBTINC  3804.0      33.768804      8.806656     0.524499     29.149239   \n",
       "\n",
       "                  50%            75%            max  \n",
       "BAD          0.000000       0.000000       1.000000  \n",
       "LOAN     16300.000000   23300.000000   89900.000000  \n",
       "MORTDUE  65206.000000   91491.000000  399412.000000  \n",
       "VALUE    89407.500000  119732.500000  855909.000000  \n",
       "YOJ          7.000000      13.000000      41.000000  \n",
       "DEROG        0.000000       0.000000      10.000000  \n",
       "DELINQ       0.000000       0.000000      15.000000  \n",
       "CLAGE      173.497696     231.876088    1168.233561  \n",
       "NINQ         1.000000       2.000000      17.000000  \n",
       "CLNO        20.000000      26.000000      71.000000  \n",
       "DEBTINC     34.818353      38.972750     203.312149  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment**: We notice that several variables (numerical and categorical) have missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data in Tensorflow\n",
    "\n",
    "Based on what I understood when you import data in Tensorflow you need two elements:\n",
    "\n",
    "**1. input_fn**: specifies how data is converted to a tf.data.Dataset that feeds the input pipeline.\n",
    "\n",
    "**2. feature column**: a construct that indicates a feature's data type.\n",
    "\n",
    "In our case, we notice that variables have missing. Then we need to impute them. Also we need to normalize data. \n",
    "\n",
    "And because we want to use Tensorflow framework, we can implement data preprocessing and transformation operations in the TensorFlow model itself. In this way, **it becomes an integral part of the model when the model is exported and deployed for predictions.**\n",
    "\n",
    "TensorFlow transformations can be accomplished in one of the following ways:\n",
    "\n",
    "1. Extending your base feature_columns (using crossed_column, embedding_column, bucketized_column, and so on).\n",
    "\n",
    "2. Implementing all of the instance-level transformation logic in a function that you call in all three input functions: train_input_fn, eval_input_fn, and serving_input_fn.\n",
    "\n",
    "3. If you are creating custom estimators, putting the code in the model_fn function.\n",
    "\n",
    "Then, we have two approaches to inputs:\n",
    "\n",
    "**1. Inside the input_fn**\n",
    "\n",
    "**2. While creating feature_column**\n",
    "\n",
    "Personally I prefer \n",
    "\n",
    "1. Preprocess data in the input_fn \n",
    "\n",
    "2. Do feature engineering while creating feature_column.\n",
    "\n",
    "About **the Data preprocessing strategy of impute missings**, \n",
    "\n",
    "- numerical variables: impute with mean\n",
    "\n",
    "- categorical variables: create 'other' class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define input_fn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = ['BAD']\n",
    "CATEGORICAL_VARIABLES = ['REASON', 'JOB']\n",
    "NUMERICAL_VARIABLES = ['LOAN', 'MORTDUE', 'VALUE', 'YOJ', 'DEROG', 'DELINQ', 'CLAGE', 'NINQ', 'CLNO', 'DEBTINC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the input function to load data into dataset\n",
    "\n",
    "def get_dataset(dataframe:pd.DataFrame, target:str, num_epochs=2, shuffle=True, batch_size=5, prefetch=True):\n",
    "    \n",
    "    def input_fn():\n",
    "        '''input_fn to read the data and impute missings'''\n",
    "        \n",
    "        # Extract\n",
    "        df = _set_categorical_type(dataframe)\n",
    "        df = _set_categorical_empty(df)\n",
    "        df = _set_numerical_type(df)\n",
    "        predictors = dict(df)\n",
    "        label = predictors.pop(target)\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((predictors, label))\n",
    "        \n",
    "        #Transform\n",
    "        dataset = dataset.map(_impute_missing_categorical)\n",
    "        dataset = dataset.map(_impute_missing_numerical)\n",
    "        dataset = dataset.repeat(num_epochs) # repeat the original dataset 3 times \n",
    "        if shuffle:\n",
    "            dataset = dataset.shuffle(buffer_size=1000, seed=8) # shuffle with a buffer of 1000 element\n",
    "        dataset = dataset.batch(5, drop_remainder=True) # small batch size to print result\n",
    "        \n",
    "        #Load\n",
    "        if prefetch:\n",
    "            dataset = dataset.prefetch(1) #just to use it. It optimize training parallelizing batch loading over CPU and GPU\n",
    "            \n",
    "        #Load: to check\n",
    "        return dataset\n",
    "    \n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_fn = get_dataset(data_train, 'BAD')\n",
    "test_input_fn = get_dataset(data_test, 'BAD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature keys: ['LOAN', 'MORTDUE', 'VALUE', 'REASON', 'JOB', 'YOJ', 'DEROG', 'DELINQ', 'CLAGE', 'NINQ', 'CLNO', 'DEBTINC']\n",
      "A batch of REASON: [b'DebtCon' b'DebtCon' b'DebtCon' b'DebtCon' b'DebtCon']\n",
      "A batch of Labels: [0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "for feature_batch, label_batch in train_input_fn().take(1):\n",
    "    print('Feature keys:', list(feature_batch.keys()))\n",
    "    print('A batch of REASON:', feature_batch['REASON'].numpy())\n",
    "    print('A batch of Labels:', label_batch.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define features and configures feature_columns\n",
    "\n",
    "In order to import our training data into TensorFlow, we need to specify what type of data each feature contains. \n",
    "\n",
    "In our case, we have:\n",
    "\n",
    "1. **Categorical Data**: 'REASON', 'JOB'\n",
    "\n",
    "2. **Numerical Data**: 'LOAN', 'MORTDUE', 'VALUE', 'YOJ', 'DEROG', 'DELINQ', 'CLAGE', 'NINQ', 'CLNO', 'DEBTINC'\n",
    "\n",
    "In TensorFlow, we indicate a feature's data type using a construct called a **feature column**. \n",
    "\n",
    "Feature columns store only a description of the feature data; they do not contain the feature data itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_input_fn()            \n",
    "# We will use this batch to demonstrate several types of feature columns\n",
    "example_batch = next(iter(train_dataset))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_features is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "[[27700.]\n",
      " [ 7700.]\n",
      " [19000.]\n",
      " [33000.]\n",
      " [14900.]]\n"
     ]
    }
   ],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/feature_column/numeric_column\n",
    "\n",
    "# Numerical variables\n",
    "\n",
    "for col_name in NUMERICAL_VARIABLES:\n",
    "    num_feature = tf.feature_column.numeric_column(col_name, dtype=tf.float64)\n",
    "    feature_columns.append(num_feature)\n",
    "    \n",
    "check_feature(feature_columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_features_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "[[1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Categorical variables\n",
    "\n",
    "labels_dict= {'REASON': ['DebtCon', 'HomeImp', 'Missing'],\n",
    "              'JOB' : ['Other', 'Sales', 'ProfExe', 'Office', 'Mgr', 'Self', 'Missing']}\n",
    "\n",
    "for col_name in CATEGORICAL_VARIABLES:\n",
    "    cat_feature = tf.feature_column.categorical_column_with_vocabulary_list(col_name, labels_dict[col_name])\n",
    "    indicator_column = tf.feature_column.indicator_column(cat_feature)\n",
    "    feature_columns.append(indicator_column)\n",
    "\n",
    "check_feature(feature_columns[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NumericColumn(key='LOAN', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n",
       " NumericColumn(key='MORTDUE', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n",
       " NumericColumn(key='VALUE', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n",
       " NumericColumn(key='YOJ', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n",
       " NumericColumn(key='DEROG', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n",
       " NumericColumn(key='DELINQ', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n",
       " NumericColumn(key='CLAGE', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n",
       " NumericColumn(key='NINQ', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n",
       " NumericColumn(key='CLNO', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n",
       " NumericColumn(key='DEBTINC', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='REASON', vocabulary_list=('DebtCon', 'HomeImp', 'Missing'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='JOB', vocabulary_list=('Other', 'Sales', 'ProfExe', 'Office', 'Mgr', 'Self', 'Missing'), dtype=tf.string, default_value=-1, num_oov_buckets=0))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a get_features function\n",
    "def get_features(num_features: list, cat_features: list, labels_dict:dict) -> list:\n",
    "    \n",
    "    # Create an empty list for feature\n",
    "    feature_columns = []\n",
    "    \n",
    "    #Get numerical features\n",
    "    for col_name in num_features:\n",
    "        num_feature = tf.feature_column.numeric_column(col_name, dtype=tf.float64)\n",
    "        feature_columns.append(num_feature)\n",
    "    \n",
    "    #Get categorical features\n",
    "    for col_name in cat_features:\n",
    "        cat_feature = tf.feature_column.categorical_column_with_vocabulary_list(col_name, labels_dict[col_name])\n",
    "        indicator_column = tf.feature_column.indicator_column(cat_feature)\n",
    "        feature_columns.append(indicator_column)\n",
    "        \n",
    "    return feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = get_features(NUMERICAL_VARIABLES, CATEGORICAL_VARIABLES, labels_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Feature Layer\n",
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmppshfzeqb', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Use Base Estimator classifier\n",
    "model_dir = tempfile.mkdtemp()\n",
    "linear_classifier_base = tf.estimator.LinearClassifier(\n",
    "    model_dir=model_dir, \n",
    "    feature_columns=feature_columns,\n",
    "    n_classes=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.8/site-packages/tensorflow/python/training/training_util.py:235: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/canned/linear.py:1471: Layer.add_variable (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/ftrl.py:111: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmppshfzeqb/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.6931472, step = 0\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 10...\n",
      "INFO:tensorflow:Saving checkpoints for 10 into /tmp/tmppshfzeqb/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 10...\n",
      "INFO:tensorflow:Loss for final step: 0.0.\n"
     ]
    }
   ],
   "source": [
    "train_input_fn = get_dataset(data_train, 'BAD', batch_size=500)\n",
    "test_input_fn = get_dataset(data_test, 'BAD', batch_size=500)\n",
    "\n",
    "linear_classifier_base = linear_classifier_base.train(input_fn=train_input_fn, steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-09-20T08:13:39Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmppshfzeqb/model.ckpt-10\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [2/20]\n",
      "INFO:tensorflow:Evaluation [4/20]\n",
      "INFO:tensorflow:Evaluation [6/20]\n",
      "INFO:tensorflow:Evaluation [8/20]\n",
      "INFO:tensorflow:Evaluation [10/20]\n",
      "INFO:tensorflow:Evaluation [12/20]\n",
      "INFO:tensorflow:Evaluation [14/20]\n",
      "INFO:tensorflow:Evaluation [16/20]\n",
      "INFO:tensorflow:Evaluation [18/20]\n",
      "INFO:tensorflow:Evaluation [20/20]\n",
      "INFO:tensorflow:Inference Time : 0.74042s\n",
      "INFO:tensorflow:Finished evaluation at 2020-09-20-08:13:40\n",
      "INFO:tensorflow:Saving dict for global step 10: accuracy = 0.89, accuracy_baseline = 0.89, auc = 0.5, auc_precision_recall = 0.11000001, average_loss = 1039.6656, global_step = 10, label/mean = 0.11, loss = 1039.6658, precision = 0.0, prediction/mean = 0.0, recall = 0.0\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10: /tmp/tmppshfzeqb/model.ckpt-10\n",
      "accuracy : 0.89\n",
      "accuracy_baseline : 0.89\n",
      "auc : 0.5\n",
      "auc_precision_recall : 0.11000001\n",
      "average_loss : 1039.6656\n",
      "label/mean : 0.11\n",
      "loss : 1039.6658\n",
      "precision : 0.0\n",
      "prediction/mean : 0.0\n",
      "recall : 0.0\n",
      "global_step : 10\n"
     ]
    }
   ],
   "source": [
    "result = linear_classifier_base.evaluate(input_fn=train_input_fn, steps=20)\n",
    "\n",
    "for key, value in result.items():\n",
    "    print(key, \":\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmppshfzeqb/model.ckpt-10\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "logits : [-7812.947]\n",
      "logistic : [0.]\n",
      "probabilities : [1. 0.]\n",
      "class_ids : [0]\n",
      "classes : [b'0']\n",
      "all_class_ids : [0 1]\n",
      "all_classes : [b'0' b'1']\n"
     ]
    }
   ],
   "source": [
    "for pred in linear_classifier_base.predict(test_input_fn):\n",
    "    for key, value in pred.items():\n",
    "        print(key, \":\", value)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
